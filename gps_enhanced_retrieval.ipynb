{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Setup: Upgrade Transformers (Run Once)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "# GPS-Enhanced Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 21:32:44.214629: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-26 21:32:44.255781: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-26 21:32:45.882981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gps_helpers import cluster_locations, compute_location_centroids, get_cluster_members, compute_gps_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: 1000 images\n",
      "Query: 500 images\n"
     ]
    }
   ],
   "source": [
    "with open(\"data/database/database_lite.json\", \"r\") as f:\n",
    "    db_data = json.load(f)\n",
    "    db_imgs = np.array(db_data[\"im_paths\"])\n",
    "    db_loc = np.array(db_data[\"loc\"])\n",
    "\n",
    "with open(\"data/query/query_lite.json\", \"r\") as f:\n",
    "    query_data = json.load(f)\n",
    "    query_imgs = np.array(query_data[\"im_paths\"])\n",
    "    query_loc = np.array(query_data[\"loc\"])\n",
    "\n",
    "with h5py.File(\"data/london_lite_gt.h5\", \"r\") as f:\n",
    "    gt_sim = f[\"sim\"][:].astype(np.uint8)\n",
    "\n",
    "print(f\"Database: {len(db_imgs)} images\")\n",
    "print(f\"Query: {len(query_imgs)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recall(ranks, pidx, ks):\n",
    "    recall_at_k = np.zeros(len(ks))\n",
    "    for qidx in range(ranks.shape[0]):\n",
    "        for i, k in enumerate(ks):\n",
    "            if np.sum(np.in1d(ranks[qidx, :k], pidx[qidx])) > 0:\n",
    "                recall_at_k[i:] += 1\n",
    "                break\n",
    "    recall_at_k /= ranks.shape[0]\n",
    "    return recall_at_k\n",
    "\n",
    "\n",
    "def apk(pidx, rank, k):\n",
    "    if len(rank) > k:\n",
    "        rank = rank[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(rank):\n",
    "        if p in pidx and p not in rank[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(pidx), k)\n",
    "\n",
    "\n",
    "def mapk(ranks, pidxs, k):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(pidxs, ranks)])\n",
    "\n",
    "\n",
    "def mapk_many(ranks, pidxs, ks):\n",
    "    return np.array([mapk(ranks, pidxs, k) for k in ks], dtype=float)\n",
    "\n",
    "\n",
    "def average_precision(relevant, retrieved):\n",
    "    precisions = []\n",
    "    rel = 0\n",
    "    for i in range(len(retrieved)):\n",
    "        if retrieved[i] in relevant:\n",
    "            rel += 1\n",
    "            precisions.append(rel / (i + 1))\n",
    "    return sum(precisions) / len(relevant) if len(relevant) > 0 else 0\n",
    "\n",
    "\n",
    "def mean_average_precision(all_relevant, all_retrieved):\n",
    "    total = 0\n",
    "    for qid in all_relevant:\n",
    "        total += average_precision(all_relevant[qid], all_retrieved.get(qid, []))\n",
    "    return total / len(all_relevant)\n",
    "\n",
    "\n",
    "def l2_normalize(x, axis=1, eps=1e-12):\n",
    "    norm = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "    return x / (norm + eps)\n",
    "\n",
    "\n",
    "def get_relevant_images(gt_similarity_matrix, query_idx):\n",
    "    return np.where(gt_similarity_matrix[query_idx, :] == 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded facebook/dinov3-vith16plus-pretrain-lvd1689m\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"facebook/dinov3-vith16plus-pretrain-lvd1689m\"\n",
    "FEAT_DIM = 1280\n",
    "POOLING = \"GeM\"\n",
    "GEM_P = 3.0\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# DINOv3 models use DINOv2 processor (compatible)\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-large\")\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "print(f\"Loaded {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features_gem(image_paths, model, processor, device, p=3.0):\n",
    "    features = np.zeros((len(image_paths), FEAT_DIM), dtype=np.float32)\n",
    "    for i, img_path in enumerate(tqdm(image_paths)):\n",
    "        img = Image.open(os.path.join(\"data/\", img_path))\n",
    "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(**inputs)\n",
    "        gem_feat = outputs.last_hidden_state[:, 1:, :].clamp(min=1e-6).pow(p).mean(dim=1).pow(1.0 / p)[0]\n",
    "        features[i] = gem_feat.cpu().numpy()\n",
    "    return l2_normalize(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting database features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [05:07<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting query features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [02:33<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database features: (1000, 1280)\n",
      "Query features: (500, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting database features...\")\n",
    "db_features = extract_features_gem(db_imgs, model, processor, device, p=GEM_P)\n",
    "\n",
    "print(\"Extracting query features...\")\n",
    "query_features = extract_features_gem(query_imgs, model, processor, device, p=GEM_P)\n",
    "\n",
    "print(f\"Database features: {db_features.shape}\")\n",
    "print(f\"Query features: {query_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## GPS Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of location clusters: 46\n",
      "Noise points: 5\n"
     ]
    }
   ],
   "source": [
    "EPS = 25\n",
    "MIN_SAMPLES = 2\n",
    "\n",
    "db_clusters = cluster_locations(db_loc, eps=EPS, min_samples=MIN_SAMPLES)\n",
    "\n",
    "n_clusters = len(np.unique(db_clusters[db_clusters >= 0]))\n",
    "n_noise = np.sum(db_clusters == -1)\n",
    "\n",
    "print(f\"Number of location clusters: {n_clusters}\")\n",
    "print(f\"Noise points: {n_noise}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Compute Location Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 46 location centroids\n"
     ]
    }
   ],
   "source": [
    "centroids, cluster_members = compute_location_centroids(db_features, db_clusters)\n",
    "\n",
    "centroid_matrix = np.zeros((len(centroids), FEAT_DIM), dtype=np.float32)\n",
    "cluster_id_to_idx = {}\n",
    "for idx, (cluster_id, centroid) in enumerate(centroids.items()):\n",
    "    centroid_matrix[idx] = centroid\n",
    "    cluster_id_to_idx[cluster_id] = idx\n",
    "\n",
    "print(f\"Computed {len(centroids)} location centroids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Prepare Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q = len(query_imgs)\n",
    "all_rel = {q: get_relevant_images(gt_sim, q) for q in range(Q)}\n",
    "pidx = [np.array(all_rel[q], dtype=int) for q in range(Q)]\n",
    "ks = [1, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Baseline: Standard Retrieval (No GPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE: Standard Retrieval (No GPS)\n",
      "============================================================\n",
      "MAP: 32.40%\n",
      "Recall@1: 39.00%   mAP@1: 39.00%\n",
      "Recall@5: 59.00%   mAP@5: 28.00%\n",
      "Recall@10: 69.60%   mAP@10: 26.98%\n",
      "Recall@20: 81.20%   mAP@20: 28.76%\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_features, db_features)\n",
    "ranks = np.argsort(-similarities, axis=1)\n",
    "\n",
    "all_ret = {q: ranks[q] for q in range(Q)}\n",
    "recall_baseline = recall(ranks, pidx, ks)\n",
    "mAPs_baseline = mapk_many(ranks, pidx, ks)\n",
    "map_baseline = mean_average_precision(all_rel, all_ret)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BASELINE: Standard Retrieval (No GPS)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_baseline*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_baseline, mAPs_baseline):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Approach A: Two-Stage Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH A: Two-Stage Retrieval\n",
      "============================================================\n",
      "MAP: 35.38%\n",
      "Recall@1: 34.40%   mAP@1: 34.40%\n",
      "Recall@5: 49.40%   mAP@5: 27.06%\n",
      "Recall@10: 60.00%   mAP@10: 28.15%\n",
      "Recall@20: 68.40%   mAP@20: 31.23%\n"
     ]
    }
   ],
   "source": [
    "centroid_similarities = cosine_similarity(query_features, centroid_matrix)\n",
    "best_clusters = np.argmax(centroid_similarities, axis=1)\n",
    "\n",
    "ranks_a = np.zeros((Q, len(db_imgs)), dtype=int)\n",
    "\n",
    "for q_idx in range(Q):\n",
    "    best_cluster_idx = best_clusters[q_idx]\n",
    "    cluster_id = list(centroids.keys())[best_cluster_idx]\n",
    "    \n",
    "    cluster_member_indices = np.array(cluster_members[cluster_id])\n",
    "    \n",
    "    cluster_sims = similarities[q_idx, cluster_member_indices]\n",
    "    sorted_cluster_indices = cluster_member_indices[np.argsort(-cluster_sims)]\n",
    "    \n",
    "    all_other_indices = np.setdiff1d(np.arange(len(db_imgs)), cluster_member_indices)\n",
    "    other_sims = similarities[q_idx, all_other_indices]\n",
    "    sorted_other_indices = all_other_indices[np.argsort(-other_sims)]\n",
    "    \n",
    "    ranks_a[q_idx] = np.concatenate([sorted_cluster_indices, sorted_other_indices])\n",
    "\n",
    "all_ret_a = {q: ranks_a[q] for q in range(Q)}\n",
    "recall_a = recall(ranks_a, pidx, ks)\n",
    "mAPs_a = mapk_many(ranks_a, pidx, ks)\n",
    "map_a = mean_average_precision(all_rel, all_ret_a)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"APPROACH A: Two-Stage Retrieval\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_a*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_a, mAPs_a):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Approach B: Weighted Similarity (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid search over alpha: 100%|██████████| 9/9 [00:25<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH B: Weighted Similarity (Best Alpha)\n",
      "============================================================\n",
      "Best alpha: 0.8\n",
      "MAP: 36.07%\n",
      "Recall@1: 36.20%   mAP@1: 36.20%\n",
      "Recall@5: 52.80%   mAP@5: 28.29%\n",
      "Recall@10: 64.20%   mAP@10: 28.83%\n",
      "Recall@20: 73.00%   mAP@20: 32.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results_b = []\n",
    "\n",
    "for alpha in tqdm(alphas, desc=\"Grid search over alpha\"):\n",
    "    combined_similarities = np.zeros_like(similarities)\n",
    "    \n",
    "    for q_idx in range(Q):\n",
    "        for db_idx in range(len(db_imgs)):\n",
    "            cluster_id = db_clusters[db_idx]\n",
    "            \n",
    "            if cluster_id >= 0:\n",
    "                cluster_idx = cluster_id_to_idx[cluster_id]\n",
    "                sim_to_centroid = centroid_similarities[q_idx, cluster_idx]\n",
    "            else:\n",
    "                sim_to_centroid = 0\n",
    "            \n",
    "            sim_to_image = similarities[q_idx, db_idx]\n",
    "            combined_similarities[q_idx, db_idx] = alpha * sim_to_centroid + (1 - alpha) * sim_to_image\n",
    "    \n",
    "    ranks_b = np.argsort(-combined_similarities, axis=1)\n",
    "    all_ret_b = {q: ranks_b[q] for q in range(Q)}\n",
    "    recall_b = recall(ranks_b, pidx, ks)\n",
    "    mAPs_b = mapk_many(ranks_b, pidx, ks)\n",
    "    map_b = mean_average_precision(all_rel, all_ret_b)\n",
    "    \n",
    "    results_b.append({\n",
    "        \"alpha\": alpha,\n",
    "        \"MAP\": map_b,\n",
    "        \"Recall@1\": recall_b[0],\n",
    "        \"Recall@5\": recall_b[1],\n",
    "        \"Recall@10\": recall_b[2],\n",
    "        \"Recall@20\": recall_b[3],\n",
    "        \"mAP@1\": mAPs_b[0],\n",
    "        \"mAP@5\": mAPs_b[1],\n",
    "        \"mAP@10\": mAPs_b[2],\n",
    "        \"mAP@20\": mAPs_b[3],\n",
    "    })\n",
    "\n",
    "best_result_b = max(results_b, key=lambda x: x[\"MAP\"])\n",
    "best_alpha = best_result_b[\"alpha\"]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"APPROACH B: Weighted Similarity (Best Alpha)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"MAP: {best_result_b['MAP']*100:.2f}%\")\n",
    "print(f\"Recall@1: {best_result_b['Recall@1']*100:.2f}%   mAP@1: {best_result_b['mAP@1']*100:.2f}%\")\n",
    "print(f\"Recall@5: {best_result_b['Recall@5']*100:.2f}%   mAP@5: {best_result_b['mAP@5']*100:.2f}%\")\n",
    "print(f\"Recall@10: {best_result_b['Recall@10']*100:.2f}%   mAP@10: {best_result_b['mAP@10']*100:.2f}%\")\n",
    "print(f\"Recall@20: {best_result_b['Recall@20']*100:.2f}%   mAP@20: {best_result_b['mAP@20']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Approach C: GPS-Filtered Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH C: GPS-Filtered Retrieval (radius=100)\n",
      "============================================================\n",
      "MAP: 58.93%\n",
      "Recall@1: 59.20%   mAP@1: 59.20%\n",
      "Recall@5: 88.60%   mAP@5: 47.01%\n",
      "Recall@10: 97.60%   mAP@10: 49.19%\n",
      "Recall@20: 99.80%   mAP@20: 55.32%\n"
     ]
    }
   ],
   "source": [
    "GPS_RADIUS = 100\n",
    "\n",
    "gps_distances = compute_gps_distances(query_loc, db_loc)\n",
    "ranks_c = np.zeros((Q, len(db_imgs)), dtype=int)\n",
    "\n",
    "for q_idx in range(Q):\n",
    "    nearby_mask = gps_distances[q_idx] <= GPS_RADIUS\n",
    "    nearby_indices = np.where(nearby_mask)[0]\n",
    "    far_indices = np.where(~nearby_mask)[0]\n",
    "    \n",
    "    nearby_sims = similarities[q_idx, nearby_indices]\n",
    "    sorted_nearby = nearby_indices[np.argsort(-nearby_sims)]\n",
    "    \n",
    "    far_sims = similarities[q_idx, far_indices]\n",
    "    sorted_far = far_indices[np.argsort(-far_sims)]\n",
    "    \n",
    "    ranks_c[q_idx] = np.concatenate([sorted_nearby, sorted_far])\n",
    "\n",
    "all_ret_c = {q: ranks_c[q] for q in range(Q)}\n",
    "recall_c = recall(ranks_c, pidx, ks)\n",
    "mAPs_c = mapk_many(ranks_c, pidx, ks)\n",
    "map_c = mean_average_precision(all_rel, all_ret_c)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"APPROACH C: GPS-Filtered Retrieval (radius={GPS_RADIUS})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_c*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_c, mAPs_c):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FINAL COMPARISON\n",
      "====================================================================================================\n",
      "                        Approach       MAP  Recall@1  Recall@5  Recall@10  Recall@20  mAP@1     mAP@5    mAP@10    mAP@20\n",
      "               Baseline (No GPS) 32.398688      39.0      59.0       69.6       81.2   39.0 28.000333 26.979112 28.762485\n",
      "          Approach A (Two-Stage) 35.384893      34.4      49.4       60.0       68.4   34.4 27.060778 28.147414 31.228387\n",
      "    Approach B (Weighted, α=0.8) 36.070755      36.2      52.8       64.2       73.0   36.2 28.294000 28.827496 32.040138\n",
      "Approach C (GPS-Filtered, r=100) 58.931081      59.2      88.6       97.6       99.8   59.2 47.009333 49.191950 55.323949\n",
      "\n",
      "Results saved to results/gps_enhanced_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Approach\": \"Baseline (No GPS)\",\n",
    "        \"MAP\": map_baseline * 100,\n",
    "        \"Recall@1\": recall_baseline[0] * 100,\n",
    "        \"Recall@5\": recall_baseline[1] * 100,\n",
    "        \"Recall@10\": recall_baseline[2] * 100,\n",
    "        \"Recall@20\": recall_baseline[3] * 100,\n",
    "        \"mAP@1\": mAPs_baseline[0] * 100,\n",
    "        \"mAP@5\": mAPs_baseline[1] * 100,\n",
    "        \"mAP@10\": mAPs_baseline[2] * 100,\n",
    "        \"mAP@20\": mAPs_baseline[3] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": \"Approach A (Two-Stage)\",\n",
    "        \"MAP\": map_a * 100,\n",
    "        \"Recall@1\": recall_a[0] * 100,\n",
    "        \"Recall@5\": recall_a[1] * 100,\n",
    "        \"Recall@10\": recall_a[2] * 100,\n",
    "        \"Recall@20\": recall_a[3] * 100,\n",
    "        \"mAP@1\": mAPs_a[0] * 100,\n",
    "        \"mAP@5\": mAPs_a[1] * 100,\n",
    "        \"mAP@10\": mAPs_a[2] * 100,\n",
    "        \"mAP@20\": mAPs_a[3] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": f\"Approach B (Weighted, α={best_alpha})\",\n",
    "        \"MAP\": best_result_b[\"MAP\"] * 100,\n",
    "        \"Recall@1\": best_result_b[\"Recall@1\"] * 100,\n",
    "        \"Recall@5\": best_result_b[\"Recall@5\"] * 100,\n",
    "        \"Recall@10\": best_result_b[\"Recall@10\"] * 100,\n",
    "        \"Recall@20\": best_result_b[\"Recall@20\"] * 100,\n",
    "        \"mAP@1\": best_result_b[\"mAP@1\"] * 100,\n",
    "        \"mAP@5\": best_result_b[\"mAP@5\"] * 100,\n",
    "        \"mAP@10\": best_result_b[\"mAP@10\"] * 100,\n",
    "        \"mAP@20\": best_result_b[\"mAP@20\"] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": f\"Approach C (GPS-Filtered, r={GPS_RADIUS})\",\n",
    "        \"MAP\": map_c * 100,\n",
    "        \"Recall@1\": recall_c[0] * 100,\n",
    "        \"Recall@5\": recall_c[1] * 100,\n",
    "        \"Recall@10\": recall_c[2] * 100,\n",
    "        \"Recall@20\": recall_c[3] * 100,\n",
    "        \"mAP@1\": mAPs_c[0] * 100,\n",
    "        \"mAP@5\": mAPs_c[1] * 100,\n",
    "        \"mAP@10\": mAPs_c[2] * 100,\n",
    "        \"mAP@20\": mAPs_c[3] * 100,\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "comparison.to_csv(\"results/gps_enhanced_comparison.csv\", index=False)\n",
    "print(\"\\nResults saved to results/gps_enhanced_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Alpha Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Approach B: Alpha Grid Search Results\n",
      " alpha       MAP  Recall@1  Recall@5  Recall@10  Recall@20  mAP@1     mAP@5    mAP@10    mAP@20\n",
      "   0.1 32.969579      39.0      58.2       70.0       81.2   39.0 28.256667 27.359787 29.310834\n",
      "   0.2 33.733421      39.4      57.8       70.4       80.2   39.4 28.548667 28.025644 29.970669\n",
      "   0.3 34.480290      39.2      57.4       71.0       79.8   39.2 28.831500 28.610519 30.645075\n",
      "   0.4 35.054027      38.4      57.8       70.6       79.2   38.4 28.958222 28.967090 31.206080\n",
      "   0.5 35.454336      38.0      56.8       68.8       78.2   38.0 28.735889 28.928123 31.542019\n",
      "   0.6 35.842832      37.2      54.8       68.4       76.6   37.2 28.660444 28.928630 31.975539\n",
      "   0.7 36.032316      36.6      54.2       65.6       75.4   36.6 28.569722 28.888478 32.057264\n",
      "   0.8 36.070755      36.2      52.8       64.2       73.0   36.2 28.294000 28.827496 32.040138\n",
      "   0.9 35.783587      35.0      50.6       61.6       69.6   35.0 27.533944 28.406957 31.627601\n"
     ]
    }
   ],
   "source": [
    "df_alpha = pd.DataFrame(results_b)\n",
    "df_alpha[\"MAP\"] = df_alpha[\"MAP\"] * 100\n",
    "df_alpha[[f\"Recall@{k}\" for k in ks]] = df_alpha[[f\"Recall@{k}\" for k in ks]] * 100\n",
    "df_alpha[[f\"mAP@{k}\" for k in ks]] = df_alpha[[f\"mAP@{k}\" for k in ks]] * 100\n",
    "\n",
    "print(\"\\nApproach B: Alpha Grid Search Results\")\n",
    "print(df_alpha.to_string(index=False))\n",
    "\n",
    "df_alpha.to_csv(\"results/approach_b_alpha_grid.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
