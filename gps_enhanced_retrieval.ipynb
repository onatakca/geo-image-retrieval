{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Setup: Upgrade Transformers (Run Once)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# GPS-Enhanced Image Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping import of cpp extensions due to incompatible torch version 2.9.0+cu126 for torchao version 0.13.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gps_helpers import cluster_locations, compute_location_centroids, get_cluster_members, compute_gps_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database: 1000 images\n",
      "Query: 500 images\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{DATA_PATH}/database/database_lite.json\", \"r\") as f:\n",
    "    db_data = json.load(f)\n",
    "    db_imgs = np.array(db_data[\"im_paths\"])\n",
    "    db_loc = np.array(db_data[\"loc\"])\n",
    "\n",
    "with open(f\"{DATA_PATH}/query/query_lite.json\", \"r\") as f:\n",
    "    query_data = json.load(f)\n",
    "    query_imgs = np.array(query_data[\"im_paths\"])\n",
    "    query_loc = np.array(query_data[\"loc\"])\n",
    "\n",
    "with h5py.File(f\"{DATA_PATH}/london_lite_gt.h5\", \"r\") as f:\n",
    "    gt_sim = f[\"sim\"][:].astype(np.uint8)\n",
    "\n",
    "print(f\"Database: {len(db_imgs)} images\")\n",
    "print(f\"Query: {len(query_imgs)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recall(ranks, pidx, ks):\n",
    "    recall_at_k = np.zeros(len(ks))\n",
    "    for qidx in range(ranks.shape[0]):\n",
    "        for i, k in enumerate(ks):\n",
    "            if np.sum(np.isin(ranks[qidx, :k], pidx[qidx])) > 0:\n",
    "                recall_at_k[i:] += 1\n",
    "                break\n",
    "    recall_at_k /= ranks.shape[0]\n",
    "    return recall_at_k\n",
    "\n",
    "\n",
    "def apk(pidx, rank, k):\n",
    "    if len(rank) > k:\n",
    "        rank = rank[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(rank):\n",
    "        if p in pidx and p not in rank[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(pidx), k)\n",
    "\n",
    "\n",
    "def mapk(ranks, pidxs, k):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(pidxs, ranks)])\n",
    "\n",
    "\n",
    "def mapk_many(ranks, pidxs, ks):\n",
    "    return np.array([mapk(ranks, pidxs, k) for k in ks], dtype=float)\n",
    "\n",
    "\n",
    "def average_precision(relevant, retrieved):\n",
    "    precisions = []\n",
    "    rel = 0\n",
    "    for i in range(len(retrieved)):\n",
    "        if retrieved[i] in relevant:\n",
    "            rel += 1\n",
    "            precisions.append(rel / (i + 1))\n",
    "    return sum(precisions) / len(relevant) if len(relevant) > 0 else 0\n",
    "\n",
    "\n",
    "def mean_average_precision(all_relevant, all_retrieved):\n",
    "    total = 0\n",
    "    for qid in all_relevant:\n",
    "        total += average_precision(all_relevant[qid], all_retrieved.get(qid, []))\n",
    "    return total / len(all_relevant)\n",
    "\n",
    "\n",
    "def l2_normalize(x, axis=1, eps=1e-12):\n",
    "    norm = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "    return x / (norm + eps)\n",
    "\n",
    "\n",
    "def get_relevant_images(gt_similarity_matrix, query_idx):\n",
    "    return np.where(gt_similarity_matrix[query_idx, :] == 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Loaded facebook/dinov3-vith16plus-pretrain-lvd1689m\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"facebook/dinov3-vith16plus-pretrain-lvd1689m\"\n",
    "FEAT_DIM = 1280\n",
    "POOLING = \"GeM\"\n",
    "GEM_P = 3.0\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# DINOv3 models use DINOv2 processor (compatible)\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "print(f\"Loaded {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features_gem(image_paths, model, processor, device, p=3.0):\n",
    "    features = np.zeros((len(image_paths), FEAT_DIM), dtype=np.float32)\n",
    "    for i, img_path in enumerate(tqdm(image_paths)):\n",
    "        img = Image.open(os.path.join(\"data/\", img_path))\n",
    "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(**inputs)\n",
    "        gem_feat = outputs.last_hidden_state[:, 1:, :].clamp(min=1e-6).pow(p).mean(dim=1).pow(1.0 / p)[0]\n",
    "        features[i] = gem_feat.cpu().numpy()\n",
    "    return l2_normalize(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting database features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:54<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting query features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:26<00:00, 18.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database features: (1000, 1280)\n",
      "Query features: (500, 1280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting database features...\")\n",
    "db_features = extract_features_gem(db_imgs, model, processor, device, p=GEM_P)\n",
    "\n",
    "print(\"Extracting query features...\")\n",
    "query_features = extract_features_gem(query_imgs, model, processor, device, p=GEM_P)\n",
    "\n",
    "print(f\"Database features: {db_features.shape}\")\n",
    "print(f\"Query features: {query_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## GPS Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of location clusters: 32\n",
      "Noise points: 0\n"
     ]
    }
   ],
   "source": [
    "EPS = 50\n",
    "MIN_SAMPLES = 2\n",
    "\n",
    "db_clusters = cluster_locations(db_loc, eps=EPS, min_samples=MIN_SAMPLES)\n",
    "\n",
    "n_clusters = len(np.unique(db_clusters[db_clusters >= 0]))\n",
    "n_noise = np.sum(db_clusters == -1)\n",
    "\n",
    "print(f\"Number of location clusters: {n_clusters}\")\n",
    "print(f\"Noise points: {n_noise}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Compute Location Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 32 location centroids\n"
     ]
    }
   ],
   "source": [
    "centroids, cluster_members = compute_location_centroids(db_features, db_clusters)\n",
    "\n",
    "centroid_matrix = np.zeros((len(centroids), FEAT_DIM), dtype=np.float32)\n",
    "cluster_id_to_idx = {}\n",
    "idx_to_cluster_id = {}\n",
    "for idx, (cluster_id, centroid) in enumerate(centroids.items()):\n",
    "    centroid_matrix[idx] = centroid\n",
    "    cluster_id_to_idx[cluster_id] = idx\n",
    "    idx_to_cluster_id[idx] = cluster_id\n",
    "\n",
    "centroid_matrix = l2_normalize(centroid_matrix, axis=1)\n",
    "print(f\"Computed {len(centroids)} location centroids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Prepare Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q = len(query_imgs)\n",
    "all_rel = {q: get_relevant_images(gt_sim, q) for q in range(Q)}\n",
    "pidx = [np.array(all_rel[q], dtype=int) for q in range(Q)]\n",
    "ks = [1, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Baseline: Standard Retrieval (No GPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE: Standard Retrieval (No GPS)\n",
      "============================================================\n",
      "MAP: 36.46%\n",
      "Recall@1: 44.00%   mAP@1: 44.00%\n",
      "Recall@5: 64.80%   mAP@5: 31.74%\n",
      "Recall@10: 73.40%   mAP@10: 31.21%\n",
      "Recall@20: 82.40%   mAP@20: 33.09%\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_features, db_features)\n",
    "ranks = np.argsort(-similarities, axis=1)\n",
    "\n",
    "all_ret = {q: ranks[q] for q in range(Q)}\n",
    "recall_baseline = recall(ranks, pidx, ks)\n",
    "mAPs_baseline = mapk_many(ranks, pidx, ks)\n",
    "map_baseline = mean_average_precision(all_rel, all_ret)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BASELINE: Standard Retrieval (No GPS)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_baseline*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_baseline, mAPs_baseline):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Approach A: Two-Stage Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_similarities = cosine_similarity(query_features, centroid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH A: Two-Stage Retrieval\n",
      "============================================================\n",
      "MAP: 40.07%\n",
      "Recall@1: 43.20%   mAP@1: 43.20%\n",
      "Recall@5: 61.60%   mAP@5: 32.13%\n",
      "Recall@10: 70.00%   mAP@10: 32.79%\n",
      "Recall@20: 77.20%   mAP@20: 35.79%\n"
     ]
    }
   ],
   "source": [
    "best_clusters = np.argmax(centroid_similarities, axis=1)\n",
    "\n",
    "ranks_a = np.zeros((Q, len(db_imgs)), dtype=int)\n",
    "\n",
    "for q_idx in range(Q):\n",
    "    best_cluster_idx = best_clusters[q_idx]\n",
    "    cluster_id = idx_to_cluster_id[best_cluster_idx]\n",
    "    \n",
    "    cluster_member_indices = np.array(cluster_members[cluster_id])\n",
    "    \n",
    "    cluster_sims = similarities[q_idx, cluster_member_indices]\n",
    "    sorted_cluster_indices = cluster_member_indices[np.argsort(-cluster_sims)]\n",
    "    \n",
    "    all_other_indices = np.setdiff1d(np.arange(len(db_imgs)), cluster_member_indices)\n",
    "    other_sims = similarities[q_idx, all_other_indices]\n",
    "    sorted_other_indices = all_other_indices[np.argsort(-other_sims)]\n",
    "    \n",
    "    ranks_a[q_idx] = np.concatenate([sorted_cluster_indices, sorted_other_indices])\n",
    "\n",
    "all_ret_a = {q: ranks_a[q] for q in range(Q)}\n",
    "recall_a = recall(ranks_a, pidx, ks)\n",
    "mAPs_a = mapk_many(ranks_a, pidx, ks)\n",
    "map_a = mean_average_precision(all_rel, all_ret_a)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"APPROACH A: Two-Stage Retrieval\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_a*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_a, mAPs_a):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Approach B: Weighted Similarity (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of location clusters: 32\n",
      "Noise points: 0\n",
      "Computed 32 location centroids\n"
     ]
    }
   ],
   "source": [
    "EPS = 50\n",
    "MIN_SAMPLES = 2\n",
    "\n",
    "db_clusters = cluster_locations(db_loc, eps=EPS, min_samples=MIN_SAMPLES)\n",
    "\n",
    "n_clusters = len(np.unique(db_clusters[db_clusters >= 0]))\n",
    "n_noise = np.sum(db_clusters == -1)\n",
    "\n",
    "print(f\"Number of location clusters: {n_clusters}\")\n",
    "print(f\"Noise points: {n_noise}\")\n",
    "\n",
    "\n",
    "centroids, cluster_members = compute_location_centroids(db_features, db_clusters)\n",
    "\n",
    "centroid_matrix = np.zeros((len(centroids), FEAT_DIM), dtype=np.float32)\n",
    "cluster_id_to_idx = {}\n",
    "idx_to_cluster_id = {}\n",
    "for idx, (cluster_id, centroid) in enumerate(centroids.items()):\n",
    "    centroid_matrix[idx] = centroid\n",
    "    cluster_id_to_idx[cluster_id] = idx\n",
    "    idx_to_cluster_id[idx] = cluster_id\n",
    "\n",
    "centroid_matrix = l2_normalize(centroid_matrix, axis=1)\n",
    "print(f\"Computed {len(centroids)} location centroids\")\n",
    "centroid_similarities = cosine_similarity(query_features, centroid_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid search over alpha: 100%|██████████| 9/9 [00:16<00:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH B: Weighted Similarity (Best Alpha)\n",
      "============================================================\n",
      "Best alpha: 0.5\n",
      "MAP: 39.23%\n",
      "Recall@1: 44.40%   mAP@1: 44.40%\n",
      "Recall@5: 65.60%   mAP@5: 32.65%\n",
      "Recall@10: 75.60%   mAP@10: 32.96%\n",
      "Recall@20: 81.80%   mAP@20: 35.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results_b = []\n",
    "\n",
    "for alpha in tqdm(alphas, desc=\"Grid search over alpha\"):\n",
    "    combined_similarities = np.zeros_like(similarities)\n",
    "    \n",
    "    for q_idx in range(Q):\n",
    "        for db_idx in range(len(db_imgs)):\n",
    "            cluster_id = db_clusters[db_idx]\n",
    "            \n",
    "            if cluster_id >= 0:\n",
    "                cluster_idx = cluster_id_to_idx[cluster_id]\n",
    "                sim_to_centroid = centroid_similarities[q_idx, cluster_idx]\n",
    "            else:\n",
    "                sim_to_centroid = 0\n",
    "            \n",
    "            sim_to_image = similarities[q_idx, db_idx]\n",
    "            combined_similarities[q_idx, db_idx] = alpha * sim_to_centroid + (1 - alpha) * sim_to_image\n",
    "    \n",
    "    ranks_b = np.argsort(-combined_similarities, axis=1)\n",
    "    all_ret_b = {q: ranks_b[q] for q in range(Q)}\n",
    "    recall_b = recall(ranks_b, pidx, ks)\n",
    "    mAPs_b = mapk_many(ranks_b, pidx, ks)\n",
    "    map_b = mean_average_precision(all_rel, all_ret_b)\n",
    "    \n",
    "    results_b.append({\n",
    "        \"alpha\": alpha,\n",
    "        \"MAP\": map_b,\n",
    "        \"Recall@1\": recall_b[0],\n",
    "        \"Recall@5\": recall_b[1],\n",
    "        \"Recall@10\": recall_b[2],\n",
    "        \"Recall@20\": recall_b[3],\n",
    "        \"mAP@1\": mAPs_b[0],\n",
    "        \"mAP@5\": mAPs_b[1],\n",
    "        \"mAP@10\": mAPs_b[2],\n",
    "        \"mAP@20\": mAPs_b[3],\n",
    "    })\n",
    "\n",
    "best_result_b = max(results_b, key=lambda x: x[\"Recall@1\"])\n",
    "best_alpha = best_result_b[\"alpha\"]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"APPROACH B: Weighted Similarity (Best Alpha)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"MAP: {best_result_b['MAP']*100:.2f}%\")\n",
    "print(f\"Recall@1: {best_result_b['Recall@1']*100:.2f}%   mAP@1: {best_result_b['mAP@1']*100:.2f}%\")\n",
    "print(f\"Recall@5: {best_result_b['Recall@5']*100:.2f}%   mAP@5: {best_result_b['mAP@5']*100:.2f}%\")\n",
    "print(f\"Recall@10: {best_result_b['Recall@10']*100:.2f}%   mAP@10: {best_result_b['mAP@10']*100:.2f}%\")\n",
    "print(f\"Recall@20: {best_result_b['Recall@20']*100:.2f}%   mAP@20: {best_result_b['mAP@20']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Approach C: GPS-Filtered Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH C: GPS-Filtered Retrieval (radius=100)\n",
      "============================================================\n",
      "MAP: 60.85%\n",
      "Recall@1: 63.20%   mAP@1: 63.20%\n",
      "Recall@5: 87.80%   mAP@5: 49.13%\n",
      "Recall@10: 97.20%   mAP@10: 51.41%\n",
      "Recall@20: 100.00%   mAP@20: 57.30%\n"
     ]
    }
   ],
   "source": [
    "GPS_RADIUS = 100\n",
    "\n",
    "gps_distances = compute_gps_distances(query_loc, db_loc)\n",
    "ranks_c = np.zeros((Q, len(db_imgs)), dtype=int)\n",
    "\n",
    "for q_idx in range(Q):\n",
    "    nearby_mask = gps_distances[q_idx] <= GPS_RADIUS\n",
    "    nearby_indices = np.where(nearby_mask)[0]\n",
    "    far_indices = np.where(~nearby_mask)[0]\n",
    "    \n",
    "    nearby_sims = similarities[q_idx, nearby_indices]\n",
    "    sorted_nearby = nearby_indices[np.argsort(-nearby_sims)]\n",
    "    \n",
    "    far_sims = similarities[q_idx, far_indices]\n",
    "    sorted_far = far_indices[np.argsort(-far_sims)]\n",
    "    \n",
    "    ranks_c[q_idx] = np.concatenate([sorted_nearby, sorted_far])\n",
    "\n",
    "all_ret_c = {q: ranks_c[q] for q in range(Q)}\n",
    "recall_c = recall(ranks_c, pidx, ks)\n",
    "mAPs_c = mapk_many(ranks_c, pidx, ks)\n",
    "map_c = mean_average_precision(all_rel, all_ret_c)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"APPROACH C: GPS-Filtered Retrieval (radius={GPS_RADIUS})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_c*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_c, mAPs_c):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FINAL COMPARISON\n",
      "====================================================================================================\n",
      "                        Approach       MAP  Recall@1  Recall@5  Recall@10  Recall@20  mAP@1     mAP@5    mAP@10    mAP@20\n",
      "               Baseline (No GPS) 36.461470      44.0      64.8       73.4       82.4   44.0 31.742111 31.205710 33.091992\n",
      "          Approach A (Two-Stage) 40.071390      43.2      61.6       70.0       77.2   43.2 32.125611 32.789575 35.788479\n",
      "    Approach B (Weighted, α=0.5) 39.227827      44.4      65.6       75.6       81.8   44.4 32.649000 32.963110 35.451960\n",
      "Approach C (GPS-Filtered, r=100) 60.853399      63.2      87.8       97.2      100.0   63.2 49.133611 51.406071 57.300976\n",
      "\n",
      "Results saved to results/gps_enhanced_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Approach\": \"Baseline (No GPS)\",\n",
    "        \"MAP\": map_baseline * 100,\n",
    "        \"Recall@1\": recall_baseline[0] * 100,\n",
    "        \"Recall@5\": recall_baseline[1] * 100,\n",
    "        \"Recall@10\": recall_baseline[2] * 100,\n",
    "        \"Recall@20\": recall_baseline[3] * 100,\n",
    "        \"mAP@1\": mAPs_baseline[0] * 100,\n",
    "        \"mAP@5\": mAPs_baseline[1] * 100,\n",
    "        \"mAP@10\": mAPs_baseline[2] * 100,\n",
    "        \"mAP@20\": mAPs_baseline[3] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": \"Approach A (Two-Stage)\",\n",
    "        \"MAP\": map_a * 100,\n",
    "        \"Recall@1\": recall_a[0] * 100,\n",
    "        \"Recall@5\": recall_a[1] * 100,\n",
    "        \"Recall@10\": recall_a[2] * 100,\n",
    "        \"Recall@20\": recall_a[3] * 100,\n",
    "        \"mAP@1\": mAPs_a[0] * 100,\n",
    "        \"mAP@5\": mAPs_a[1] * 100,\n",
    "        \"mAP@10\": mAPs_a[2] * 100,\n",
    "        \"mAP@20\": mAPs_a[3] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": f\"Approach B (Weighted, α={best_alpha})\",\n",
    "        \"MAP\": best_result_b[\"MAP\"] * 100,\n",
    "        \"Recall@1\": best_result_b[\"Recall@1\"] * 100,\n",
    "        \"Recall@5\": best_result_b[\"Recall@5\"] * 100,\n",
    "        \"Recall@10\": best_result_b[\"Recall@10\"] * 100,\n",
    "        \"Recall@20\": best_result_b[\"Recall@20\"] * 100,\n",
    "        \"mAP@1\": best_result_b[\"mAP@1\"] * 100,\n",
    "        \"mAP@5\": best_result_b[\"mAP@5\"] * 100,\n",
    "        \"mAP@10\": best_result_b[\"mAP@10\"] * 100,\n",
    "        \"mAP@20\": best_result_b[\"mAP@20\"] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": f\"Approach C (GPS-Filtered, r={GPS_RADIUS})\",\n",
    "        \"MAP\": map_c * 100,\n",
    "        \"Recall@1\": recall_c[0] * 100,\n",
    "        \"Recall@5\": recall_c[1] * 100,\n",
    "        \"Recall@10\": recall_c[2] * 100,\n",
    "        \"Recall@20\": recall_c[3] * 100,\n",
    "        \"mAP@1\": mAPs_c[0] * 100,\n",
    "        \"mAP@5\": mAPs_c[1] * 100,\n",
    "        \"mAP@10\": mAPs_c[2] * 100,\n",
    "        \"mAP@20\": mAPs_c[3] * 100,\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "comparison.to_csv(\"results/gps_enhanced_comparison.csv\", index=False)\n",
    "print(\"\\nResults saved to results/gps_enhanced_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Alpha Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Approach B: Alpha Grid Search Results\n",
      " alpha       MAP  Recall@1  Recall@5  Recall@10  Recall@20  mAP@1     mAP@5    mAP@10    mAP@20\n",
      "   0.1 37.083606      44.2      65.6       74.2       81.8   44.2 32.030944 31.637477 33.611121\n",
      "   0.2 37.682317      44.2      65.4       75.0       82.0   44.2 32.329944 32.071909 34.100365\n",
      "   0.3 38.235874      44.2      65.8       75.2       82.0   44.2 32.452722 32.424211 34.516383\n",
      "   0.4 38.794110      44.2      66.0       75.6       82.4   44.2 32.719111 32.676867 35.044726\n",
      "   0.5 39.227827      44.4      65.6       75.6       81.8   44.4 32.649000 32.963110 35.451960\n",
      "   0.6 39.552104      44.2      65.0       74.8       81.6   44.2 32.622444 33.051359 35.763928\n",
      "   0.7 39.774517      43.8      63.8       73.6       80.8   43.8 32.593611 33.096785 35.870922\n",
      "   0.8 39.756476      43.0      63.4       71.8       78.0   43.0 32.290278 32.889714 35.709419\n",
      "   0.9 39.960322      43.6      62.6       71.0       76.8   43.6 32.349944 32.947992 35.857313\n"
     ]
    }
   ],
   "source": [
    "df_alpha = pd.DataFrame(results_b)\n",
    "df_alpha[\"MAP\"] = df_alpha[\"MAP\"] * 100\n",
    "df_alpha[[f\"Recall@{k}\" for k in ks]] = df_alpha[[f\"Recall@{k}\" for k in ks]] * 100\n",
    "df_alpha[[f\"mAP@{k}\" for k in ks]] = df_alpha[[f\"mAP@{k}\" for k in ks]] * 100\n",
    "\n",
    "print(\"\\nApproach B: Alpha Grid Search Results\")\n",
    "print(df_alpha.to_string(index=False))\n",
    "\n",
    "df_alpha.to_csv(\"results/approach_b_alpha_grid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Using 2 backbones (dinov3-vith16plus-pretrain-lvd1689m and openai/clip-vit-base-patch32) + approach A and B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Loaded facebook/dinov3-vith16plus-pretrain-lvd1689m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded openai/clip-vit-base-patch32\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAMES = [\n",
    "    \"facebook/dinov3-vith16plus-pretrain-lvd1689m\",\n",
    "    \"openai/clip-vit-base-patch32\"\n",
    "]\n",
    "\n",
    "FEAT_DIM = 1280 +768\n",
    "POOLING = \"GeM\"\n",
    "GEM_P = 3.0\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "dino_processor = AutoImageProcessor.from_pretrained(MODEL_NAMES[0])\n",
    "dino_model = AutoModel.from_pretrained(MODEL_NAMES[0]).to(device)\n",
    "print(f\"Loaded {MODEL_NAMES[0]}\")\n",
    "\n",
    "clip_model = CLIPModel.from_pretrained(MODEL_NAMES[1]).to(device)\n",
    "clip_processor = CLIPProcessor.from_pretrained(MODEL_NAMES[1])\n",
    "print(f\"Loaded {MODEL_NAMES[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_features_gem_dino_clip(image_paths, dino_model, clip_model, \n",
    "                                    dino_processor, clip_processor, device, p=3.0):\n",
    "    num_images = len(image_paths)\n",
    "    \n",
    "    clip_feats = np.zeros((num_images, 768), dtype=np.float32)\n",
    "    dino_feats = np.zeros((num_images, 1280), dtype=np.float32)\n",
    "    \n",
    "    clip_model = clip_model.to(device)\n",
    "    dino_model = dino_model.to(device)\n",
    "    \n",
    "    clip_model.eval()\n",
    "    dino_model.eval()\n",
    "    \n",
    "    for i, img_path in enumerate(tqdm(image_paths)):\n",
    "        img = Image.open(os.path.join(\"data/\", img_path))\n",
    "        \n",
    "        clip_inputs = clip_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "        with torch.inference_mode():\n",
    "            vision_outputs = clip_model.vision_model(**clip_inputs)\n",
    "        clip_tokens = vision_outputs.last_hidden_state[:, 1:, :]\n",
    "        clip_gem = clip_tokens.clamp(min=1e-6).pow(p).mean(dim=1).pow(1./p)[0].cpu().numpy()\n",
    "        clip_feats[i] = clip_gem\n",
    "        \n",
    "        dino_inputs = dino_processor(images=img, return_tensors=\"pt\").to(device)\n",
    "        with torch.inference_mode():\n",
    "            dino_outputs = dino_model(**dino_inputs)\n",
    "        dino_tokens = dino_outputs.last_hidden_state[:, 1:, :]\n",
    "        dino_gem = dino_tokens.clamp(min=1e-6).pow(p).mean(dim=1).pow(1./p)[0].cpu().numpy()\n",
    "        dino_feats[i] = dino_gem\n",
    "    \n",
    "    clip_feats = l2_normalize(clip_feats, axis=1)\n",
    "    dino_feats = l2_normalize(dino_feats, axis=1)\n",
    "    \n",
    "    combined_feats = np.concatenate([clip_feats, dino_feats], axis=1)\n",
    "    \n",
    "    return combined_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting database features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:59<00:00, 16.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting query features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:29<00:00, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database features: (1000, 2048)\n",
      "Query features: (500, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting database features...\")\n",
    "db_features = extract_features_gem_dino_clip(db_imgs, dino_model,clip_model, dino_processor,clip_processor, device, p=GEM_P)\n",
    "\n",
    "print(\"Extracting query features...\")\n",
    "query_features = extract_features_gem_dino_clip(query_imgs, dino_model,clip_model, dino_processor,clip_processor, device, p=GEM_P)\n",
    "\n",
    "print(f\"Database features: {db_features.shape}\")\n",
    "print(f\"Query features: {query_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### GPS clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of location clusters: 32\n",
      "Noise points: 0\n"
     ]
    }
   ],
   "source": [
    "EPS = 50\n",
    "MIN_SAMPLES = 2\n",
    "\n",
    "db_clusters = cluster_locations(db_loc, eps=EPS, min_samples=MIN_SAMPLES)\n",
    "\n",
    "n_clusters = len(np.unique(db_clusters[db_clusters >= 0]))\n",
    "n_noise = np.sum(db_clusters == -1)\n",
    "\n",
    "print(f\"Number of location clusters: {n_clusters}\")\n",
    "print(f\"Noise points: {n_noise}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Compute location centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed 32 location centroids\n"
     ]
    }
   ],
   "source": [
    "centroids, cluster_members = compute_location_centroids(db_features, db_clusters)\n",
    "\n",
    "centroid_matrix = np.zeros((len(centroids), FEAT_DIM), dtype=np.float32)\n",
    "cluster_id_to_idx = {}\n",
    "idx_to_cluster_id = {}\n",
    "for idx, (cluster_id, centroid) in enumerate(centroids.items()):\n",
    "    centroid_matrix[idx] = centroid\n",
    "    cluster_id_to_idx[cluster_id] = idx\n",
    "    idx_to_cluster_id[idx] = cluster_id\n",
    "\n",
    "centroid_matrix = l2_normalize(centroid_matrix, axis=1)\n",
    "print(f\"Computed {len(centroids)} location centroids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Prepare ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Q = len(query_imgs)\n",
    "all_rel = {q: get_relevant_images(gt_sim, q) for q in range(Q)}\n",
    "pidx = [np.array(all_rel[q], dtype=int) for q in range(Q)]\n",
    "ks = [1, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Baseline: retrieval (no gps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE: Standard Retrieval (No GPS)\n",
      "============================================================\n",
      "MAP: 37.45%\n",
      "Recall@1: 44.80%   mAP@1: 44.80%\n",
      "Recall@5: 66.60%   mAP@5: 32.70%\n",
      "Recall@10: 76.00%   mAP@10: 32.23%\n",
      "Recall@20: 85.00%   mAP@20: 34.03%\n"
     ]
    }
   ],
   "source": [
    "similarities = cosine_similarity(query_features, db_features)\n",
    "ranks = np.argsort(-similarities, axis=1)\n",
    "\n",
    "all_ret = {q: ranks[q] for q in range(Q)}\n",
    "recall_baseline = recall(ranks, pidx, ks)\n",
    "mAPs_baseline = mapk_many(ranks, pidx, ks)\n",
    "map_baseline = mean_average_precision(all_rel, all_ret)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"BASELINE: Standard Retrieval (No GPS)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_baseline*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_baseline, mAPs_baseline):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Approach A: Two-Stage Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "centroid_similarities = cosine_similarity(query_features, centroid_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH A: Two-Stage Retrieval\n",
      "============================================================\n",
      "MAP: 40.89%\n",
      "Recall@1: 44.40%   mAP@1: 44.40%\n",
      "Recall@5: 62.00%   mAP@5: 33.46%\n",
      "Recall@10: 70.40%   mAP@10: 33.83%\n",
      "Recall@20: 77.00%   mAP@20: 36.69%\n"
     ]
    }
   ],
   "source": [
    "best_clusters = np.argmax(centroid_similarities, axis=1)\n",
    "\n",
    "ranks_a = np.zeros((Q, len(db_imgs)), dtype=int)\n",
    "\n",
    "for q_idx in range(Q):\n",
    "    best_cluster_idx = best_clusters[q_idx]\n",
    "    cluster_id = idx_to_cluster_id[best_cluster_idx]\n",
    "    \n",
    "    cluster_member_indices = np.array(cluster_members[cluster_id])\n",
    "    \n",
    "    cluster_sims = similarities[q_idx, cluster_member_indices]\n",
    "    sorted_cluster_indices = cluster_member_indices[np.argsort(-cluster_sims)]\n",
    "    \n",
    "    all_other_indices = np.setdiff1d(np.arange(len(db_imgs)), cluster_member_indices)\n",
    "    other_sims = similarities[q_idx, all_other_indices]\n",
    "    sorted_other_indices = all_other_indices[np.argsort(-other_sims)]\n",
    "    \n",
    "    ranks_a[q_idx] = np.concatenate([sorted_cluster_indices, sorted_other_indices])\n",
    "\n",
    "all_ret_a = {q: ranks_a[q] for q in range(Q)}\n",
    "recall_a = recall(ranks_a, pidx, ks)\n",
    "mAPs_a = mapk_many(ranks_a, pidx, ks)\n",
    "map_a = mean_average_precision(all_rel, all_ret_a)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"APPROACH A: Two-Stage Retrieval\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_a*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_a, mAPs_a):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Approach B: Weighted Similarity (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of location clusters: 32\n",
      "Noise points: 0\n",
      "Computed 32 location centroids\n"
     ]
    }
   ],
   "source": [
    "EPS = 50\n",
    "MIN_SAMPLES = 2\n",
    "\n",
    "db_clusters = cluster_locations(db_loc, eps=EPS, min_samples=MIN_SAMPLES)\n",
    "\n",
    "n_clusters = len(np.unique(db_clusters[db_clusters >= 0]))\n",
    "n_noise = np.sum(db_clusters == -1)\n",
    "\n",
    "print(f\"Number of location clusters: {n_clusters}\")\n",
    "print(f\"Noise points: {n_noise}\")\n",
    "\n",
    "\n",
    "centroids, cluster_members = compute_location_centroids(db_features, db_clusters)\n",
    "\n",
    "centroid_matrix = np.zeros((len(centroids), FEAT_DIM), dtype=np.float32)\n",
    "cluster_id_to_idx = {}\n",
    "idx_to_cluster_id = {}\n",
    "for idx, (cluster_id, centroid) in enumerate(centroids.items()):\n",
    "    centroid_matrix[idx] = centroid\n",
    "    cluster_id_to_idx[cluster_id] = idx\n",
    "    idx_to_cluster_id[idx] = cluster_id\n",
    "\n",
    "centroid_matrix = l2_normalize(centroid_matrix, axis=1)\n",
    "print(f\"Computed {len(centroids)} location centroids\")\n",
    "centroid_similarities = cosine_similarity(query_features, centroid_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid search over alpha: 100%|██████████| 9/9 [00:16<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH B: Weighted Similarity (Best Alpha)\n",
      "============================================================\n",
      "Best alpha: 0.6\n",
      "MAP: 40.88%\n",
      "Recall@1: 46.40%   mAP@1: 46.40%\n",
      "Recall@5: 66.60%   mAP@5: 34.36%\n",
      "Recall@10: 76.20%   mAP@10: 34.57%\n",
      "Recall@20: 81.80%   mAP@20: 36.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "results_b = []\n",
    "\n",
    "for alpha in tqdm(alphas, desc=\"Grid search over alpha\"):\n",
    "    combined_similarities = np.zeros_like(similarities)\n",
    "    \n",
    "    for q_idx in range(Q):\n",
    "        for db_idx in range(len(db_imgs)):\n",
    "            cluster_id = db_clusters[db_idx]\n",
    "            \n",
    "            if cluster_id >= 0:\n",
    "                cluster_idx = cluster_id_to_idx[cluster_id]\n",
    "                sim_to_centroid = centroid_similarities[q_idx, cluster_idx]\n",
    "            else:\n",
    "                sim_to_centroid = 0\n",
    "            \n",
    "            sim_to_image = similarities[q_idx, db_idx]\n",
    "            combined_similarities[q_idx, db_idx] = alpha * sim_to_centroid + (1 - alpha) * sim_to_image\n",
    "    \n",
    "    ranks_b = np.argsort(-combined_similarities, axis=1)\n",
    "    all_ret_b = {q: ranks_b[q] for q in range(Q)}\n",
    "    recall_b = recall(ranks_b, pidx, ks)\n",
    "    mAPs_b = mapk_many(ranks_b, pidx, ks)\n",
    "    map_b = mean_average_precision(all_rel, all_ret_b)\n",
    "    \n",
    "    results_b.append({\n",
    "        \"alpha\": alpha,\n",
    "        \"MAP\": map_b,\n",
    "        \"Recall@1\": recall_b[0],\n",
    "        \"Recall@5\": recall_b[1],\n",
    "        \"Recall@10\": recall_b[2],\n",
    "        \"Recall@20\": recall_b[3],\n",
    "        \"mAP@1\": mAPs_b[0],\n",
    "        \"mAP@5\": mAPs_b[1],\n",
    "        \"mAP@10\": mAPs_b[2],\n",
    "        \"mAP@20\": mAPs_b[3],\n",
    "    })\n",
    "\n",
    "best_result_b = max(results_b, key=lambda x: x[\"Recall@1\"])\n",
    "best_alpha = best_result_b[\"alpha\"]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"APPROACH B: Weighted Similarity (Best Alpha)\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best alpha: {best_alpha}\")\n",
    "print(f\"MAP: {best_result_b['MAP']*100:.2f}%\")\n",
    "print(f\"Recall@1: {best_result_b['Recall@1']*100:.2f}%   mAP@1: {best_result_b['mAP@1']*100:.2f}%\")\n",
    "print(f\"Recall@5: {best_result_b['Recall@5']*100:.2f}%   mAP@5: {best_result_b['mAP@5']*100:.2f}%\")\n",
    "print(f\"Recall@10: {best_result_b['Recall@10']*100:.2f}%   mAP@10: {best_result_b['mAP@10']*100:.2f}%\")\n",
    "print(f\"Recall@20: {best_result_b['Recall@20']*100:.2f}%   mAP@20: {best_result_b['mAP@20']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Approach C: GPS-Filtered Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "APPROACH C: GPS-Filtered Retrieval (radius=100)\n",
      "============================================================\n",
      "MAP: 61.55%\n",
      "Recall@1: 63.20%   mAP@1: 63.20%\n",
      "Recall@5: 89.80%   mAP@5: 50.34%\n",
      "Recall@10: 97.20%   mAP@10: 52.03%\n",
      "Recall@20: 100.00%   mAP@20: 58.09%\n"
     ]
    }
   ],
   "source": [
    "GPS_RADIUS = 100\n",
    "\n",
    "gps_distances = compute_gps_distances(query_loc, db_loc)\n",
    "ranks_c = np.zeros((Q, len(db_imgs)), dtype=int)\n",
    "\n",
    "for q_idx in range(Q):\n",
    "    nearby_mask = gps_distances[q_idx] <= GPS_RADIUS\n",
    "    nearby_indices = np.where(nearby_mask)[0]\n",
    "    far_indices = np.where(~nearby_mask)[0]\n",
    "    \n",
    "    nearby_sims = similarities[q_idx, nearby_indices]\n",
    "    sorted_nearby = nearby_indices[np.argsort(-nearby_sims)]\n",
    "    \n",
    "    far_sims = similarities[q_idx, far_indices]\n",
    "    sorted_far = far_indices[np.argsort(-far_sims)]\n",
    "    \n",
    "    ranks_c[q_idx] = np.concatenate([sorted_nearby, sorted_far])\n",
    "\n",
    "all_ret_c = {q: ranks_c[q] for q in range(Q)}\n",
    "recall_c = recall(ranks_c, pidx, ks)\n",
    "mAPs_c = mapk_many(ranks_c, pidx, ks)\n",
    "map_c = mean_average_precision(all_rel, all_ret_c)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"APPROACH C: GPS-Filtered Retrieval (radius={GPS_RADIUS})\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"MAP: {map_c*100:.2f}%\")\n",
    "for k, r, m in zip(ks, recall_c, mAPs_c):\n",
    "    print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "### Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "FINAL COMPARISON\n",
      "====================================================================================================\n",
      "                        Approach       MAP  Recall@1  Recall@5  Recall@10  Recall@20  mAP@1     mAP@5    mAP@10    mAP@20\n",
      "               Baseline (No GPS) 37.447127      44.8      66.6       76.0       85.0   44.8 32.698889 32.232180 34.028459\n",
      "          Approach A (Two-Stage) 40.886735      44.4      62.0       70.4       77.0   44.4 33.459833 33.831942 36.690555\n",
      "    Approach B (Weighted, α=0.6) 40.884586      46.4      66.6       76.2       81.8   46.4 34.358167 34.570013 36.978218\n",
      "Approach C (GPS-Filtered, r=100) 61.548770      63.2      89.8       97.2      100.0   63.2 50.338833 52.032332 58.094165\n"
     ]
    }
   ],
   "source": [
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Approach\": \"Baseline (No GPS)\",\n",
    "        \"MAP\": map_baseline * 100,\n",
    "        \"Recall@1\": recall_baseline[0] * 100,\n",
    "        \"Recall@5\": recall_baseline[1] * 100,\n",
    "        \"Recall@10\": recall_baseline[2] * 100,\n",
    "        \"Recall@20\": recall_baseline[3] * 100,\n",
    "        \"mAP@1\": mAPs_baseline[0] * 100,\n",
    "        \"mAP@5\": mAPs_baseline[1] * 100,\n",
    "        \"mAP@10\": mAPs_baseline[2] * 100,\n",
    "        \"mAP@20\": mAPs_baseline[3] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": \"Approach A (Two-Stage)\",\n",
    "        \"MAP\": map_a * 100,\n",
    "        \"Recall@1\": recall_a[0] * 100,\n",
    "        \"Recall@5\": recall_a[1] * 100,\n",
    "        \"Recall@10\": recall_a[2] * 100,\n",
    "        \"Recall@20\": recall_a[3] * 100,\n",
    "        \"mAP@1\": mAPs_a[0] * 100,\n",
    "        \"mAP@5\": mAPs_a[1] * 100,\n",
    "        \"mAP@10\": mAPs_a[2] * 100,\n",
    "        \"mAP@20\": mAPs_a[3] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": f\"Approach B (Weighted, α={best_alpha})\",\n",
    "        \"MAP\": best_result_b[\"MAP\"] * 100,\n",
    "        \"Recall@1\": best_result_b[\"Recall@1\"] * 100,\n",
    "        \"Recall@5\": best_result_b[\"Recall@5\"] * 100,\n",
    "        \"Recall@10\": best_result_b[\"Recall@10\"] * 100,\n",
    "        \"Recall@20\": best_result_b[\"Recall@20\"] * 100,\n",
    "        \"mAP@1\": best_result_b[\"mAP@1\"] * 100,\n",
    "        \"mAP@5\": best_result_b[\"mAP@5\"] * 100,\n",
    "        \"mAP@10\": best_result_b[\"mAP@10\"] * 100,\n",
    "        \"mAP@20\": best_result_b[\"mAP@20\"] * 100,\n",
    "    },\n",
    "    {\n",
    "        \"Approach\": f\"Approach C (GPS-Filtered, r={GPS_RADIUS})\",\n",
    "        \"MAP\": map_c * 100,\n",
    "        \"Recall@1\": recall_c[0] * 100,\n",
    "        \"Recall@5\": recall_c[1] * 100,\n",
    "        \"Recall@10\": recall_c[2] * 100,\n",
    "        \"Recall@20\": recall_c[3] * 100,\n",
    "        \"mAP@1\": mAPs_c[0] * 100,\n",
    "        \"mAP@5\": mAPs_c[1] * 100,\n",
    "        \"mAP@10\": mAPs_c[2] * 100,\n",
    "        \"mAP@20\": mAPs_c[3] * 100,\n",
    "    },\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FINAL COMPARISON\")\n",
    "print(\"=\" * 100)\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "comparison.to_csv(\"results/gps_enhanced_comparison_dino+clip.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Alpha Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Approach B: Alpha Grid Search Results\n",
      " alpha       MAP  Recall@1  Recall@5  Recall@10  Recall@20  mAP@1     mAP@5    mAP@10    mAP@20\n",
      "   0.1 38.076366      45.0      66.4       76.8       85.2   45.0 33.006333 32.740402 34.621068\n",
      "   0.2 38.786303      45.6      67.0       77.0       84.8   45.6 33.440889 33.205196 35.218386\n",
      "   0.3 39.488197      45.8      67.4       77.0       83.6   45.8 33.945889 33.720074 35.874158\n",
      "   0.4 40.114763      46.2      66.8       76.8       83.6   46.2 34.130389 34.194663 36.445780\n",
      "   0.5 40.634004      46.2      67.2       76.2       82.6   46.2 34.428889 34.474736 36.835643\n",
      "   0.6 40.884586      46.4      66.6       76.2       81.8   46.4 34.358167 34.570013 36.978218\n",
      "   0.7 40.948265      46.2      65.6       74.6       80.4   46.2 34.180167 34.474785 36.945413\n",
      "   0.8 40.967179      45.4      64.0       73.2       78.6   45.4 33.930833 34.267663 36.880895\n",
      "   0.9 40.958091      44.8      63.6       72.4       77.0   44.8 33.719167 34.094798 36.873809\n"
     ]
    }
   ],
   "source": [
    "df_alpha = pd.DataFrame(results_b)\n",
    "df_alpha[\"MAP\"] = df_alpha[\"MAP\"] * 100\n",
    "df_alpha[[f\"Recall@{k}\" for k in ks]] = df_alpha[[f\"Recall@{k}\" for k in ks]] * 100\n",
    "df_alpha[[f\"mAP@{k}\" for k in ks]] = df_alpha[[f\"mAP@{k}\" for k in ks]] * 100\n",
    "\n",
    "print(\"\\nApproach B: Alpha Grid Search Results\")\n",
    "print(df_alpha.to_string(index=False))\n",
    "\n",
    "df_alpha.to_csv(\"results/approach_b_alpha_grid_dino+clip.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gemma3)",
   "language": "python",
   "name": "gemma3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
