{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef69ad4a-9e75-4db6-a6e0-8b7dc3b9060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877b32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from transformers import CLIPModel, CLIPProcessor\n",
    "from transformers import AutoProcessor, AutoModelForZeroShotImageClassification\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd345726-74f1-4a0d-ab2f-460d26cb854a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"geo-image-retrieval\") \n",
    "import perception_models.core.vision_encoder.pe as pe\n",
    "import core.vision_encoder.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ac1b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map\n",
    "with open(\"../data/database/database_lite.json\",\"r\") as f:\n",
    "    m_idx = json.load(f)\n",
    "    m_imgs = np.array(m_idx[\"im_paths\"])\n",
    "    m_loc=np.array(m_idx[\"loc\"])\n",
    "\n",
    "# query\n",
    "with open(\"../data/query/query_lite.json\",\"r\") as f:\n",
    "    q_idx=json.load(f)\n",
    "    q_imgs=np.array(q_idx[\"im_paths\"])\n",
    "    q_loc=np.array(q_idx[\"loc\"])\n",
    "    \n",
    "# loading the relevance judgements\n",
    "with h5py.File(\"../data/london_lite_gt.h5\",\"r\") as f:\n",
    "   fovs = f[\"fov\"][:]\n",
    "   sim = f[\"sim\"][:].astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85314ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(new_session=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fe1df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(ranks, pidx, ks):\n",
    "    recall_at_k = np.zeros(len(ks))\n",
    "    for qidx in range(ranks.shape[0]):\n",
    "        for i, k in enumerate(ks):\n",
    "            if np.sum(np.in1d(ranks[qidx,:k], pidx[qidx])) > 0:\n",
    "                recall_at_k[i:] += 1\n",
    "                break\n",
    "\n",
    "    recall_at_k /= ranks.shape[0]\n",
    "    return recall_at_k\n",
    "\n",
    "def apk(pidx, rank, k):\n",
    "    if len(rank)>k:\n",
    "        rank = rank[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(rank):\n",
    "        if p in pidx and p not in rank[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    return score / min(len(pidx), k)\n",
    "\n",
    "def mapk(ranks, pidxs, k):\n",
    "\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(pidxs, ranks)])\n",
    "\n",
    "def mapk_many(ranks, pidxs, ks):\n",
    "    return np.array([mapk(ranks, pidxs, k) for k in ks], dtype=float)\n",
    "\n",
    "def average_precision(relevant, retrieved):\n",
    "   precisions = []\n",
    "   rel = 0\n",
    "   for i in range(0, len(retrieved)):\n",
    "      if retrieved[i] in relevant:\n",
    "         rel += 1\n",
    "         precisions.append(rel/(i+1))\n",
    "   return sum(precisions) / len(relevant)\n",
    "\n",
    "def mean_average_precision(all_relevant, all_retrieved):\n",
    "   total = 0\n",
    "   count = 0\n",
    "   for qid in all_relevant: \n",
    "      total += average_precision(all_relevant[qid], all_retrieved.get(qid, []))\n",
    "      count += 1\n",
    "   return total / count\n",
    "\n",
    "\n",
    "def l2_normalize(x, axis=1, eps=1e-12):\n",
    "   norm = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "   return x / (norm + eps)\n",
    "\n",
    "def get_relevant_images(gt_similarity_matrix, query_idx):\n",
    "   return np.where(gt_similarity_matrix[query_idx, :] == 1)[0]\n",
    "\n",
    "def get_retrieved_images(feature_matrix, query_idx):\n",
    "   return np.argsort(-feature_matrix[query_idx])\n",
    "\n",
    "def save_results_to_csv(model_name, map_value, recall_at_k, mAPs, csv_path=\"./results/feature_extraction_evaluation.csv\"):\n",
    "    results_dict = {\n",
    "        \"models_name\": model_name,\n",
    "        \"MAP\": map_value * 100,\n",
    "        \"Recall@1\": recall_at_k[0] * 100,\n",
    "        \"Recall@5\": recall_at_k[1] * 100,\n",
    "        \"Recall@10\": recall_at_k[2] * 100,\n",
    "        \"Recall@20\": recall_at_k[3] * 100,\n",
    "        \"mAP@1\": mAPs[0] * 100,\n",
    "        \"mAP@5\": mAPs[1] * 100,\n",
    "        \"mAP@10\": mAPs[2] * 100,\n",
    "        \"mAP@20\": mAPs[3] * 100\n",
    "    }\n",
    "\n",
    "    os.makedirs(os.path.dirname(csv_path), exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(csv_path):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if model_name in df['models_name'].values:\n",
    "            df.loc[df['models_name'] == model_name] = pd.Series(results_dict)\n",
    "        else:\n",
    "            df = pd.concat([df, pd.DataFrame([results_dict])], ignore_index=True)\n",
    "    else:\n",
    "        df = pd.DataFrame([results_dict])\n",
    "    \n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78ad8663",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCEPTION_MODELS = {\n",
    "    'PE-Core-T16-384' : 512,\n",
    "    'PE-Core-S16-384' : 512, \n",
    "    'PE-Core-B16-224' : 1024,\n",
    "    'PE-Core-L14-336' : 1024, \n",
    "    'PE-Core-G14-448' : 1280,   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c0027-e1eb-447b-825e-40c13743caf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Loading model: PE-Core-T16-384\n",
      "================================================================================\n",
      "\n",
      "Missing keys for loading vision encoder: []\n",
      "Unexpected keys for loading vision encoder: []\n",
      "\n",
      "================================================================================\n",
      "Loading model: PE-Core-S16-384\n",
      "================================================================================\n",
      "\n",
      "Missing keys for loading vision encoder: []\n",
      "Unexpected keys for loading vision encoder: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:15<00:00, 62.55it/s]\n",
      "100%|██████████| 500/500 [00:07<00:00, 64.68it/s]\n",
      "/tmp/ipykernel_6301/2298934414.py:5: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  if np.sum(np.in1d(ranks[qidx,:k], pidx[qidx])) > 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Evaluating: CLS_token\n",
      "============================================================\n",
      "MODEL: PE-Core-S16-384\n",
      "Pooling: CLS_token\n",
      "MAP: 18.82%\n",
      "Recall@1: 24.80%   mAP@1: 24.80%\n",
      "Recall@5: 43.60%   mAP@5: 15.58%\n",
      "Recall@10: 57.20%   mAP@10: 14.28%\n",
      "Recall@20: 70.00%   mAP@20: 15.06%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Loading model: PE-Core-B16-224\n",
      "================================================================================\n",
      "\n",
      "Missing keys for loading vision encoder: []\n",
      "Unexpected keys for loading vision encoder: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:13<00:00, 72.94it/s]\n",
      "100%|██████████| 500/500 [00:06<00:00, 74.52it/s]\n",
      "/tmp/ipykernel_6301/2298934414.py:5: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  if np.sum(np.in1d(ranks[qidx,:k], pidx[qidx])) > 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Evaluating: CLS_token\n",
      "============================================================\n",
      "MODEL: PE-Core-B16-224\n",
      "Pooling: CLS_token\n",
      "MAP: 25.13%\n",
      "Recall@1: 28.80%   mAP@1: 28.80%\n",
      "Recall@5: 57.80%   mAP@5: 20.77%\n",
      "Recall@10: 69.20%   mAP@10: 20.18%\n",
      "Recall@20: 79.60%   mAP@20: 21.39%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Loading model: PE-Core-L14-336\n",
      "================================================================================\n",
      "\n",
      "Missing keys for loading vision encoder: []\n",
      "Unexpected keys for loading vision encoder: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:55<00:00, 18.00it/s]\n",
      "100%|██████████| 500/500 [00:28<00:00, 17.79it/s]\n",
      "/tmp/ipykernel_6301/2298934414.py:5: DeprecationWarning: `in1d` is deprecated. Use `np.isin` instead.\n",
      "  if np.sum(np.in1d(ranks[qidx,:k], pidx[qidx])) > 0:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Evaluating: CLS_token\n",
      "============================================================\n",
      "MODEL: PE-Core-L14-336\n",
      "Pooling: CLS_token\n",
      "MAP: 23.96%\n",
      "Recall@1: 31.00%   mAP@1: 31.00%\n",
      "Recall@5: 57.20%   mAP@5: 20.93%\n",
      "Recall@10: 65.60%   mAP@10: 19.67%\n",
      "Recall@20: 76.20%   mAP@20: 20.68%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Loading model: PE-Core-G14-448\n",
      "================================================================================\n",
      "\n",
      "Missing keys for loading vision encoder: []\n",
      "Unexpected keys for loading vision encoder: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 426/500 [03:03<00:31,  2.32it/s]]"
     ]
    }
   ],
   "source": [
    "for MODEL_TO_USE, feat_dim in PERCEPTION_MODELS.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Loading model: {MODEL_TO_USE}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    try:\n",
    "        model = pe.VisionTransformer.from_config(MODEL_TO_USE, pretrained=True)\n",
    "        preprocess = transforms.get_image_transform(model.image_size)\n",
    "            \n",
    "        device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "        model = model.to(device)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "        \n",
    "    if os.path.exists(f\"./results/pooling_comparison/{MODEL_TO_USE.replace('/', '_')}_pooling_comparison.csv\"):\n",
    "        continue\n",
    "\n",
    "    m_feats_cls = np.zeros((len(m_imgs), feat_dim), dtype=np.float32)\n",
    "    \n",
    "    \n",
    "    for i, img_name in enumerate(tqdm(m_imgs)):\n",
    "        img = Image.open(os.path.join('../data/', img_name)).convert(\"RGB\")\n",
    "        img = preprocess(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            vision_outputs = model(img)[0]\n",
    "        \n",
    "        m_feats_cls[i] = vision_outputs.squeeze().cpu().numpy()\n",
    "    \n",
    "    q_feats_cls = np.zeros((len(q_imgs), feat_dim), dtype=np.float32)\n",
    "        \n",
    "    for i, img_name in enumerate(tqdm(q_imgs)):\n",
    "        img = Image.open(os.path.join('../data/', img_name)).convert(\"RGB\")\n",
    "        img = preprocess(img).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            vision_outputs = model(img)[0]\n",
    "        \n",
    "        q_feats_cls[i] = vision_outputs.squeeze().cpu().numpy()\n",
    "    \n",
    "    m_feats_cls = l2_normalize(m_feats_cls, axis=1)\n",
    "    q_feats_cls = l2_normalize(q_feats_cls, axis=1)\n",
    "    \n",
    "    pooling_strategies = {\n",
    "        \"CLS_token\": (q_feats_cls, m_feats_cls)\n",
    "    }\n",
    "    \n",
    "    all_results = []\n",
    "    best = None\n",
    "    best_map = 0.0\n",
    "    best_recall_at_k = None\n",
    "    best_mAPs = None\n",
    "    \n",
    "    for pooling_name, (q_feats, m_feats) in pooling_strategies.items():\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Evaluating: {pooling_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        similarities = cosine_similarity(q_feats, m_feats)\n",
    "        \n",
    "        all_rel = {}\n",
    "        all_ret = {}\n",
    "        for query_idx in range(len(similarities)):\n",
    "            all_rel[query_idx] = get_relevant_images(sim, query_idx)\n",
    "            all_ret[query_idx] = get_retrieved_images(similarities, query_idx)\n",
    "\n",
    "        ranks = np.argsort(-similarities, axis=1) \n",
    "        \n",
    "        Q = similarities.shape[0]\n",
    "        pidx = [np.array(all_rel[q], dtype=int) for q in range(Q)]\n",
    "        \n",
    "        ks = [1, 5, 10, 20]\n",
    "        recall_at_k = recall(ranks, pidx, ks)\n",
    "        mAPs = mapk_many(ranks, pidx, ks)\n",
    "        map_value = mean_average_precision(all_rel, all_ret)\n",
    "        \n",
    "        if best is None or recall_at_k[0] > best_recall_at_k[0]:\n",
    "            best_map = map_value\n",
    "            best = pooling_name\n",
    "            best_recall_at_k = recall_at_k\n",
    "            best_mAPs = mAPs\n",
    "        \n",
    "        print(f\"MODEL: {MODEL_TO_USE}\")\n",
    "        print(f\"Pooling: {pooling_name}\")\n",
    "        print(f\"MAP: {map_value*100:.2f}%\")\n",
    "        for k, r, m in zip(ks, recall_at_k, mAPs):\n",
    "            print(f\"Recall@{k}: {r*100:.2f}%   mAP@{k}: {m*100:.2f}%\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "        result_dict = {\n",
    "            \"models_name\": f\"{MODEL_TO_USE}_{pooling_name}\",\n",
    "            \"MAP\": map_value * 100,\n",
    "            \"Recall@1\": recall_at_k[0] * 100,\n",
    "            \"Recall@5\": recall_at_k[1] * 100,\n",
    "            \"Recall@10\": recall_at_k[2] * 100,\n",
    "            \"Recall@20\": recall_at_k[3] * 100,\n",
    "            \"mAP@1\": mAPs[0] * 100,\n",
    "            \"mAP@5\": mAPs[1] * 100,\n",
    "            \"mAP@10\": mAPs[2] * 100,\n",
    "            \"mAP@20\": mAPs[3] * 100\n",
    "        }\n",
    "        all_results.append(result_dict)\n",
    "    \n",
    "    df_results = pd.DataFrame(all_results)\n",
    "    CSV_PATH = f\"./results/pooling_comparison/{MODEL_TO_USE.replace('/', '_')}_pooling_comparison.csv\"\n",
    "    os.makedirs(os.path.dirname(CSV_PATH), exist_ok=True)\n",
    "    df_results.to_csv(CSV_PATH, index=False)\n",
    "    \n",
    "    df_main = save_results_to_csv(f\"{MODEL_TO_USE}_{best}\", best_map, best_recall_at_k, best_mAPs)\n",
    "    \n",
    "    del model\n",
    "    if torch.cuda.is_available(): torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3e846-3179-4a48-b86b-e300290beeec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(\"./results/feature_extraction_evaluation.csv\")\n",
    "print(\"\\n=== FINAL MODEL COMPARISON (Best pooling for each) ===\")\n",
    "print(df_final[['models_name', 'MAP', 'Recall@1', 'Recall@20']].sort_values('Recall@1', ascending=False).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (perception_models)",
   "language": "python",
   "name": "perception_models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
