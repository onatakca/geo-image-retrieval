{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f4548c-15e1-4ded-b79b-fad77c63ab27",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "# GPS-Enhanced Image Retrieval - exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df254f9f-6245-4c96-9465-08cfeb927c09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.neighbors import BallTree\n",
    "import h5py\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from gps_helpers import cluster_locations, compute_location_centroids, get_cluster_members, compute_gps_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf21899-3b11-41dd-bcd9-3dcbf76af9ff",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa819f05-a69e-434e-aed2-35242dee79aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\"\n",
    "with open(f\"{DATA_PATH}/database/database_lite.json\", \"r\") as f:\n",
    "    db_data = json.load(f)\n",
    "    db_imgs = np.array(db_data[\"im_paths\"])\n",
    "    db_loc = np.array(db_data[\"loc\"])\n",
    "\n",
    "with open(f\"{DATA_PATH}/query/query_lite.json\", \"r\") as f:\n",
    "    query_data = json.load(f)\n",
    "    query_imgs = np.array(query_data[\"im_paths\"])\n",
    "    query_loc = np.array(query_data[\"loc\"])\n",
    "\n",
    "with h5py.File(f\"{DATA_PATH}/london_lite_gt.h5\", \"r\") as f:\n",
    "    gt_sim = f[\"sim\"][:].astype(np.uint8)\n",
    "\n",
    "print(f\"Database: {len(db_imgs)} images\")\n",
    "print(f\"Query: {len(query_imgs)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e54ff-bbd0-4cbd-9fe2-a6d0a6bc6565",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217011dd-9ede-4dee-bb6b-05117b2b5571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recall(ranks, pidx, ks):\n",
    "    recall_at_k = np.zeros(len(ks))\n",
    "    for qidx in range(ranks.shape[0]):\n",
    "        for i, k in enumerate(ks):\n",
    "            if np.sum(np.in1d(ranks[qidx, :k], pidx[qidx])) > 0:\n",
    "                recall_at_k[i:] += 1\n",
    "                break\n",
    "    recall_at_k /= ranks.shape[0]\n",
    "    return recall_at_k\n",
    "\n",
    "\n",
    "def apk(pidx, rank, k):\n",
    "    if len(rank) > k:\n",
    "        rank = rank[:k]\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(rank):\n",
    "        if p in pidx and p not in rank[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "    return score / min(len(pidx), k)\n",
    "\n",
    "\n",
    "def mapk(ranks, pidxs, k):\n",
    "    return np.mean([apk(a, p, k) for a, p in zip(pidxs, ranks)])\n",
    "\n",
    "\n",
    "def mapk_many(ranks, pidxs, ks):\n",
    "    return np.array([mapk(ranks, pidxs, k) for k in ks], dtype=float)\n",
    "\n",
    "\n",
    "def average_precision(relevant, retrieved):\n",
    "    precisions = []\n",
    "    rel = 0\n",
    "    for i in range(len(retrieved)):\n",
    "        if retrieved[i] in relevant:\n",
    "            rel += 1\n",
    "            precisions.append(rel / (i + 1))\n",
    "    return sum(precisions) / len(relevant) if len(relevant) > 0 else 0\n",
    "\n",
    "\n",
    "def mean_average_precision(all_relevant, all_retrieved):\n",
    "    total = 0\n",
    "    for qid in all_relevant:\n",
    "        total += average_precision(all_relevant[qid], all_retrieved.get(qid, []))\n",
    "    return total / len(all_relevant)\n",
    "\n",
    "\n",
    "def l2_normalize(x, axis=1, eps=1e-12):\n",
    "    norm = np.linalg.norm(x, axis=axis, keepdims=True)\n",
    "    return x / (norm + eps)\n",
    "\n",
    "\n",
    "def get_relevant_images(gt_similarity_matrix, query_idx):\n",
    "    return np.where(gt_similarity_matrix[query_idx, :] == 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cbe2f3-361b-4087-aca8-da63538e4f7a",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df0027-8d0d-4250-8c3e-9d930a301b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"facebook/dinov3-vith16plus-pretrain-lvd1689m\"\n",
    "FEAT_DIM = 1280\n",
    "POOLING = \"GeM\"\n",
    "GEM_P = 3.0\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# DINOv3 models use DINOv2 processor (compatible)\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_NAME)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
    "print(f\"Loaded {MODEL_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b4a41-f4a5-4a80-b9cd-b1c807f5d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_gem(image_paths, model, processor, device, p=3.0):\n",
    "    features = np.zeros((len(image_paths), FEAT_DIM), dtype=np.float32)\n",
    "    for i, img_path in enumerate(tqdm(image_paths)):\n",
    "        img = Image.open(os.path.join(\"data/\", img_path))\n",
    "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
    "        with torch.inference_mode():\n",
    "            outputs = model(**inputs)\n",
    "        gem_feat = outputs.last_hidden_state[:, 1:, :].clamp(min=1e-6).pow(p).mean(dim=1).pow(1.0 / p)[0]\n",
    "        features[i] = gem_feat.cpu().numpy()\n",
    "    return l2_normalize(features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f570e-b4e0-4ac2-8221-9dc72a012938",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Extracting database features...\")\n",
    "db_features = extract_features_gem(db_imgs, model, processor, device, p=GEM_P)\n",
    "\n",
    "print(\"Extracting query features...\")\n",
    "query_features = extract_features_gem(query_imgs, model, processor, device, p=GEM_P)\n",
    "\n",
    "print(f\"Database features: {db_features.shape}\")\n",
    "print(f\"Query features: {query_features.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45619e20-26e3-4ba7-b480-167b17a09ddd",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## GPS Clustering -> finding optimal epsilon (distance) and minimum number of samples per location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcd742-8870-409d-a535-393dd6d969dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pairwise_distances(db_loc[:, :2])\n",
    "print(np.median(d[d>0])) # media sitance, interesting for our location grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644dd0d-f788-4449-a078-466b2c1a8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = db_loc[:, :2].astype(np.float64)  \n",
    "tree = BallTree(coords, metric='euclidean')\n",
    "\n",
    "dist2, _ = tree.query(coords, k=2)\n",
    "nn = dist2[:, 1] \n",
    "\n",
    "k = MIN_SAMPLES  \n",
    "distk, _ = tree.query(coords, k=k+1)\n",
    "kdist = distk[:, k]\n",
    "\n",
    "print(\"1-NN (m) percentiles:\", np.percentile(nn, [10,25,50,75,90]))\n",
    "print(f\"{k}-NN (m) percentiles:\", np.percentile(kdist, [10,25,50,75,90]))\n",
    "# directly can be used for clustering, but is interesting since this is quite dense, so location filtering does not help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17233f5f-cbd9-4438-bbfc-2f8d797169bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPS_ = [10, 20, 30, 40, 50, 75,100] \n",
    "MIN_SAMPLES_ = [2,4,8]\n",
    "best_option_recall1 = 0.0\n",
    "\n",
    "for EPS in EPS_:\n",
    "    for MIN_SAMPLES in MIN_SAMPLES_:\n",
    "        db_clusters = cluster_locations(db_loc, eps=EPS, min_samples=MIN_SAMPLES)\n",
    "\n",
    "        n_clusters = len(np.unique(db_clusters[db_clusters >= 0]))\n",
    "        n_noise = np.sum(db_clusters == -1)\n",
    "\n",
    "        centroids, cluster_members = compute_location_centroids(db_features, db_clusters)\n",
    "\n",
    "        centroid_matrix = np.zeros((len(centroids), FEAT_DIM), dtype=np.float32)\n",
    "        cluster_id_to_idx = {}\n",
    "        idx_to_cluster_id = {}\n",
    "        for idx, (cluster_id, centroid) in enumerate(centroids.items()):\n",
    "            centroid_matrix[idx] = centroid\n",
    "            cluster_id_to_idx[cluster_id] = idx\n",
    "            idx_to_cluster_id[idx] = cluster_id\n",
    "\n",
    "        centroid_matrix = l2_normalize(centroid_matrix, axis=1)\n",
    "        centroid_similarities = cosine_similarity(query_features, centroid_matrix)\n",
    "        best_clusters = np.argmax(centroid_similarities, axis=1)\n",
    "\n",
    "        ranks_a = np.zeros((Q, len(db_imgs)), dtype=int)\n",
    "\n",
    "        for q_idx in range(Q):\n",
    "            best_cluster_idx = best_clusters[q_idx]\n",
    "            cluster_id = idx_to_cluster_id[best_cluster_idx]\n",
    "\n",
    "            cluster_member_indices = np.array(cluster_members[cluster_id])\n",
    "\n",
    "            cluster_sims = similarities[q_idx, cluster_member_indices]\n",
    "            sorted_cluster_indices = cluster_member_indices[np.argsort(-cluster_sims)]\n",
    "\n",
    "            all_other_indices = np.setdiff1d(np.arange(len(db_imgs)), cluster_member_indices)\n",
    "            other_sims = similarities[q_idx, all_other_indices]\n",
    "            sorted_other_indices = all_other_indices[np.argsort(-other_sims)]\n",
    "\n",
    "            ranks_a[q_idx] = np.concatenate([sorted_cluster_indices, sorted_other_indices])\n",
    "\n",
    "        all_ret_a = {q: ranks_a[q] for q in range(Q)}\n",
    "        recall_a = recall(ranks_a, pidx, ks)\n",
    "        mAPs_a = mapk_many(ranks_a, pidx, ks)\n",
    "        map_a = mean_average_precision(all_rel, all_ret_a)\n",
    "        \n",
    "        if recall_a[0] >best_option_recall1:\n",
    "            best_option_recall1 = recall_a[0]\n",
    "            best_option = (EPS, MIN_SAMPLES)\n",
    "            \n",
    "print(f\"best option is {best_option}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d84f5f-adfc-409e-ba61-0d4ed21c3f89",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "## Exploring if approach B works better when using smaller distances between centroids/more centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef148748-a203-4668-be9a-a21ea5fc52ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS_ = [10, 20, 30, 40, 50, 75, 100]\n",
    "MIN_SAMPLES_ = [2, 4, 8]\n",
    "ALPHAS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "\n",
    "results = []\n",
    "best_overall = None\n",
    "best_recall1 = 0.0\n",
    "\n",
    "for EPS in EPS_:\n",
    "    for MIN_SAMPLES in MIN_SAMPLES_:\n",
    "        db_clusters = cluster_locations(db_loc, eps=EPS, min_samples=MIN_SAMPLES)\n",
    "        n_clusters = len(np.unique(db_clusters[db_clusters >= 0]))\n",
    "        n_noise = np.sum(db_clusters == -1)\n",
    "        print(f\"[EPS={EPS}, MIN_SAMPLES={MIN_SAMPLES}] clusters={n_clusters}, noise={n_noise}\")\n",
    "\n",
    "        centroids, cluster_members = compute_location_centroids(db_features, db_clusters)\n",
    "\n",
    "        centroid_matrix = np.zeros((len(centroids), FEAT_DIM), dtype=np.float32)\n",
    "        cluster_id_to_idx, idx_to_cluster_id = {}, {}\n",
    "        for idx, (cluster_id, centroid) in enumerate(centroids.items()):\n",
    "            centroid_matrix[idx] = centroid\n",
    "            cluster_id_to_idx[cluster_id] = idx\n",
    "            idx_to_cluster_id[idx] = cluster_id\n",
    "\n",
    "        centroid_matrix = l2_normalize(centroid_matrix, axis=1)\n",
    "        similarities = cosine_similarity(query_features, db_features)\n",
    "        centroid_similarities = cosine_similarity(query_features, centroid_matrix)\n",
    "\n",
    "        for alpha in ALPHAS:\n",
    "            combined_similarities = np.empty_like(similarities)\n",
    "            for q_idx in range(Q):\n",
    "                for db_idx in range(len(db_imgs)):\n",
    "                    cluster_id = db_clusters[db_idx]\n",
    "                    if cluster_id >= 0:\n",
    "                        cluster_idx = cluster_id_to_idx[cluster_id]\n",
    "                        sim_centroid = centroid_similarities[q_idx, cluster_idx]\n",
    "                    else:\n",
    "                        sim_centroid = 0\n",
    "                    sim_image = similarities[q_idx, db_idx]\n",
    "                    combined_similarities[q_idx, db_idx] = (\n",
    "                        alpha * sim_centroid + (1 - alpha) * sim_image\n",
    "                    )\n",
    "\n",
    "            ranks = np.argsort(-combined_similarities, axis=1)\n",
    "            all_ret = {q: ranks[q] for q in range(Q)}\n",
    "\n",
    "            recall_vals = recall(ranks, pidx, ks)\n",
    "            mAPs = mapk_many(ranks, pidx, ks)\n",
    "            MAP = mean_average_precision(all_rel, all_ret)\n",
    "\n",
    "            result = {\n",
    "                \"EPS\": EPS,\n",
    "                \"MIN_SAMPLES\": MIN_SAMPLES,\n",
    "                \"alpha\": alpha,\n",
    "                \"MAP\": MAP,\n",
    "                \"Recall@1\": recall_vals[0],\n",
    "                \"Recall@5\": recall_vals[1],\n",
    "                \"Recall@10\": recall_vals[2],\n",
    "                \"Recall@20\": recall_vals[3],\n",
    "            }\n",
    "            results.append(result)\n",
    "\n",
    "            if recall_vals[0] > best_recall1:\n",
    "                best_recall1 = recall_vals[0]\n",
    "                best_overall = result\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"BEST CONFIGURATION (by Recall@1)\")\n",
    "print(\"=\"*60)\n",
    "print(best_overall)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gemma3)",
   "language": "python",
   "name": "gemma3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
